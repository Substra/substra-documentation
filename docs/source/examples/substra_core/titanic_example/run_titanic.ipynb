{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Running Substra with a single organisation on the Titanic dataset\n",
        "\n",
        "\n",
        "This example is based on [the similarly named Kaggle challenge](https://www.kaggle.com/c/titanic/overview).\n",
        "\n",
        "In this example, we work on the Titanic tabular dataset. This is a classification problem\n",
        "that uses a random forest model.\n",
        "\n",
        "Here you will learn how to interact with Substra, more specifically:\n",
        "\n",
        "- instantiating Substra Client\n",
        "- creating and registering assets\n",
        "- launching an experiment\n",
        "\n",
        "\n",
        "There is no federated learning in this example, training and testing will happen on only one [Organization](https://docs.substra.org/en/stable/additional/glossary.html#term-Organization).\n",
        "\n",
        "\n",
        "To run this example, you need to download and unzip the assets needed to run it in the same directory as used this example:\n",
        "\n",
        "- [assets required to run this example](../../../tmp/titanic_assets.zip)\n",
        "\n",
        "Please ensure to have all the libraries installed. A *requirements.txt* file is included in the zip file, where you can run the command `pip install -r requirements.txt` to install them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import all the dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/tfouqueray/.virtualenvs/substra3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "import substra\n",
        "from substra.sdk.schemas import (\n",
        "    AssetKind,\n",
        "    DataSampleSpec,\n",
        "    DatasetSpec,\n",
        "    FunctionSpec,\n",
        "    FunctionInputSpec,\n",
        "    FunctionOutputSpec,\n",
        "    Permissions,\n",
        "    TaskSpec,\n",
        "    ComputeTaskOutputSpec,\n",
        "    InputRef,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Instantiating the Substra Client\n",
        "\n",
        "The client allows us to interact with the Substra platform.\n",
        "\n",
        "By setting the argument `backend_type` to:\n",
        "\n",
        " - `docker` all tasks will be executed from docker containers (default)\n",
        " - `subprocess` all tasks will be executed from Python subprocesses (faster)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "client = substra.Client(client_name=\"org-1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creation and Registration of the assets\n",
        "\n",
        "Every asset will be created in respect to predefined schemas (Spec) previously imported from\n",
        "substra.sdk.schemas. To register assets, asset [schemas](https://docs.substra.org/en/stable/documentation/references/sdk_schemas.html#schemas)\n",
        "are first instantiated and the specs are then registered, which generates the real assets.\n",
        "\n",
        "Permissions are defined when registering assets. In a nutshell:\n",
        "\n",
        "- Data cannot be seen once it's registered on the platform.\n",
        "- Metadata are visible by all the users of a channel.\n",
        "- Permissions allow you to execute a function on a certain dataset.\n",
        "\n",
        "In a remote deployment, setting the parameter `public` to false means that the dataset can only be used by tasks in\n",
        "the same organization or by organizations that are in the `authorized_ids`. However, these permissions are ignored in local mode.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "permissions = Permissions(public=True, authorized_ids=[])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we need to define the asset directory. You should have already downloaded the assets folder as stated above.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "root_dir = Path.cwd()\n",
        "assets_directory = root_dir / \"assets\"\n",
        "assert assets_directory.is_dir(), \"\"\"Did not find the asset directory, a directory called 'assets' is\n",
        "expected in the same location as this py file\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Registering data samples and dataset\n",
        "\n",
        "A dataset represents the data in Substra. It is made up of an opener, which is a script used to load the\n",
        "data from files into memory. You can find more details about datasets\n",
        "in the [API reference](https://docs.substra.org/en/stable/documentation/api_reference.html#sdk-reference).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset key 4757bfc6-aba2-44b0-bd13-01bb1d1b6b2f\n"
          ]
        }
      ],
      "source": [
        "dataset = DatasetSpec(\n",
        "    name=\"Titanic dataset - Org 1\",\n",
        "    type=\"csv\",\n",
        "    data_opener=assets_directory / \"dataset\" / \"titanic_opener.py\",\n",
        "    description=assets_directory / \"dataset\" / \"description.md\",\n",
        "    permissions=permissions,\n",
        "    logs_permission=permissions,\n",
        ")\n",
        "\n",
        "dataset_key = client.add_dataset(dataset)\n",
        "print(f\"Dataset key {dataset_key}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adding train data samples\n",
        "\n",
        "The dataset object itself is an empty shell. Data samples are needed in order to add actual data.\n",
        "A data sample contains subfolders containing a single data file like a CSV and the key identifying\n",
        "the dataset it is linked to.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 data samples were registered\n"
          ]
        }
      ],
      "source": [
        "train_data_sample_folder = assets_directory / \"train_data_samples\"\n",
        "train_data_sample_keys = client.add_data_samples(\n",
        "    DataSampleSpec(\n",
        "        paths=list(train_data_sample_folder.glob(\"*\")),\n",
        "        data_manager_keys=[dataset_key],\n",
        "    )\n",
        ")\n",
        "\n",
        "print(f\"{len(train_data_sample_keys)} data samples were registered\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adding test data samples\n",
        "\n",
        "The operation is done again but with the test data samples.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2 data samples were registered\n"
          ]
        }
      ],
      "source": [
        "test_data_sample_folder = assets_directory / \"test_data_samples\"\n",
        "test_data_sample_keys = client.add_data_samples(\n",
        "    DataSampleSpec(\n",
        "        paths=list(test_data_sample_folder.glob(\"*\")),\n",
        "        data_manager_keys=[dataset_key],\n",
        "    )\n",
        ")\n",
        "\n",
        "print(f\"{len(test_data_sample_keys)} data samples were registered\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The data has now been added as an asset through the data samples both for the training and\n",
        "testing part of our experience.\n",
        "\n",
        "### Adding Metrics\n",
        "\n",
        "A metric corresponds to a function to evaluate the performance of a model on a dataset.\n",
        "Concretely, a metric corresponds to an archive (tar or zip file) containing:\n",
        "\n",
        "- Python scripts that implement the metric computation\n",
        "- a Dockerfile on which the user can specify the required dependencies of the Python scripts\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metric key d179166e-3fde-4ce9-a0d8-cc4aff27cb99\n"
          ]
        }
      ],
      "source": [
        "inputs_metrics = [\n",
        "    FunctionInputSpec(identifier=\"datasamples\", kind=AssetKind.data_sample, optional=False, multiple=True),\n",
        "    FunctionInputSpec(identifier=\"opener\", kind=AssetKind.data_manager, optional=False, multiple=False),\n",
        "    FunctionInputSpec(identifier=\"predictions\", kind=AssetKind.model, optional=False, multiple=False),\n",
        "]\n",
        "\n",
        "outputs_metrics = [FunctionOutputSpec(identifier=\"performance\", kind=AssetKind.performance, multiple=False)]\n",
        "\n",
        "\n",
        "METRICS_DOCKERFILE_FILES = [\n",
        "    assets_directory / \"metric\" / \"titanic_metrics.py\",\n",
        "    assets_directory / \"metric\" / \"Dockerfile\",\n",
        "]\n",
        "\n",
        "metric_archive_path = assets_directory / \"metric\" / \"metrics.zip\"\n",
        "\n",
        "with zipfile.ZipFile(metric_archive_path, \"w\") as z:\n",
        "    for filepath in METRICS_DOCKERFILE_FILES:\n",
        "        z.write(filepath, arcname=os.path.basename(filepath))\n",
        "\n",
        "metric_function = FunctionSpec(\n",
        "    inputs=inputs_metrics,\n",
        "    outputs=outputs_metrics,\n",
        "    name=\"Testing with Accuracy metric\",\n",
        "    description=assets_directory / \"metric\" / \"description.md\",\n",
        "    file=metric_archive_path,\n",
        "    permissions=permissions,\n",
        ")\n",
        "\n",
        "metric_key = client.add_function(metric_function)\n",
        "\n",
        "print(f\"Metric key {metric_key}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adding Function\n",
        "\n",
        "A [Function](https://docs.substra.org/en/stable/documentation/concepts.html#function) specifies the method to train a model on a dataset or the method to aggregate models.\n",
        "Concretely, a function corresponds to an archive (tar or zip file) containing:\n",
        "\n",
        "- One or more Python scripts that implement the function. It is required to define `train` and `predict` functions.\n",
        "- A Dockerfile in which the user can specify the required dependencies of the Python scripts.\n",
        "  This Dockerfile also specifies the method name to execute (either `train` or `predict` here).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train function key d8ec2e64-3510-48b5-b2e4-8b4b4dbb944d\n"
          ]
        }
      ],
      "source": [
        "ALGO_TRAIN_DOCKERFILE_FILES = [\n",
        "    assets_directory / \"function_random_forest/titanic_function_rf.py\",\n",
        "    assets_directory / \"function_random_forest/train/Dockerfile\",\n",
        "]\n",
        "\n",
        "train_archive_path = assets_directory / \"function_random_forest\" / \"function_random_forest.zip\"\n",
        "with zipfile.ZipFile(train_archive_path, \"w\") as z:\n",
        "    for filepath in ALGO_TRAIN_DOCKERFILE_FILES:\n",
        "        z.write(filepath, arcname=os.path.basename(filepath))\n",
        "\n",
        "train_function_inputs = [\n",
        "    FunctionInputSpec(identifier=\"datasamples\", kind=AssetKind.data_sample, optional=False, multiple=True),\n",
        "    FunctionInputSpec(identifier=\"opener\", kind=AssetKind.data_manager, optional=False, multiple=False),\n",
        "]\n",
        "\n",
        "train_function_outputs = [FunctionOutputSpec(identifier=\"model\", kind=AssetKind.model, multiple=False)]\n",
        "\n",
        "train_function = FunctionSpec(\n",
        "    name=\"Training with Random Forest\",\n",
        "    inputs=train_function_inputs,\n",
        "    outputs=train_function_outputs,\n",
        "    description=assets_directory / \"function_random_forest\" / \"description.md\",\n",
        "    file=train_archive_path,\n",
        "    permissions=permissions,\n",
        ")\n",
        "\n",
        "\n",
        "train_function_key = client.add_function(train_function)\n",
        "\n",
        "print(f\"Train function key {train_function_key}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The predict function uses the same Python file as the function used for training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predict function key a965e850-2f81-484a-997e-69d073473141\n"
          ]
        }
      ],
      "source": [
        "ALGO_PREDICT_DOCKERFILE_FILES = [\n",
        "    assets_directory / \"function_random_forest/titanic_function_rf.py\",\n",
        "    assets_directory / \"function_random_forest/predict/Dockerfile\",\n",
        "]\n",
        "\n",
        "predict_archive_path = assets_directory / \"function_random_forest\" / \"function_random_forest.zip\"\n",
        "with zipfile.ZipFile(predict_archive_path, \"w\") as z:\n",
        "    for filepath in ALGO_PREDICT_DOCKERFILE_FILES:\n",
        "        z.write(filepath, arcname=os.path.basename(filepath))\n",
        "\n",
        "predict_function_inputs = [\n",
        "    FunctionInputSpec(identifier=\"datasamples\", kind=AssetKind.data_sample, optional=False, multiple=True),\n",
        "    FunctionInputSpec(identifier=\"opener\", kind=AssetKind.data_manager, optional=False, multiple=False),\n",
        "    FunctionInputSpec(identifier=\"models\", kind=AssetKind.model, optional=False, multiple=False),\n",
        "]\n",
        "\n",
        "predict_function_outputs = [FunctionOutputSpec(identifier=\"predictions\", kind=AssetKind.model, multiple=False)]\n",
        "\n",
        "predict_function_spec = FunctionSpec(\n",
        "    name=\"Predicting with Random Forest\",\n",
        "    inputs=predict_function_inputs,\n",
        "    outputs=predict_function_outputs,\n",
        "    description=assets_directory / \"function_random_forest\" / \"description.md\",\n",
        "    file=predict_archive_path,\n",
        "    permissions=permissions,\n",
        ")\n",
        "\n",
        "predict_function_key = client.add_function(predict_function_spec)\n",
        "\n",
        "print(f\"Predict function key {predict_function_key}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The data, the functions and the metric are now registered.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Registering tasks\n",
        "\n",
        "The next step is to register the actual machine learning tasks.\n",
        "First a training task is registered which will produce a machine learning model.\n",
        "Then a testing task is registered to test the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train task key 3fba7b54-801b-4659-b606-7caef32aeadf\n"
          ]
        }
      ],
      "source": [
        "data_manager_input = [InputRef(identifier=\"opener\", asset_key=dataset_key)]\n",
        "train_data_sample_inputs = [InputRef(identifier=\"datasamples\", asset_key=key) for key in train_data_sample_keys]\n",
        "test_data_sample_inputs = [InputRef(identifier=\"datasamples\", asset_key=key) for key in test_data_sample_keys]\n",
        "\n",
        "train_task = TaskSpec(\n",
        "    function_key=train_function_key,\n",
        "    inputs=data_manager_input + train_data_sample_inputs,\n",
        "    outputs={\"model\": ComputeTaskOutputSpec(permissions=permissions)},\n",
        "    worker=client.organization_info().organization_id,\n",
        ")\n",
        "\n",
        "train_task_key = client.add_task(train_task)\n",
        "\n",
        "print(f\"Train task key {train_task_key}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In local mode, the registered task is executed at once:\n",
        "the registration function returns a value once the task has been executed.\n",
        "\n",
        "In deployed mode, the registered task is added to a queue and treated asynchronously: this means that the\n",
        "code that registers the tasks keeps executing. To wait for a task to be done, create a loop and get the task\n",
        "every ``n`` seconds until its status is done or failed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:  Python 3.5-3.7 will be deprecated on August 8th, 2023. Please use Python version 3.8 and up.\n",
            "\n",
            "If you have a compatible Python interpreter installed, you can use it by setting\n",
            "the CLOUDSDK_PYTHON environment variable to point to it.\n",
            "\n",
            "WARNING:  Python 3.5-3.7 will be deprecated on August 8th, 2023. Please use Python version 3.8 and up.\n",
            "\n",
            "If you have a compatible Python interpreter installed, you can use it by setting\n",
            "the CLOUDSDK_PYTHON environment variable to point to it.\n",
            "\n",
            "WARNING:  Python 3.5-3.7 will be deprecated on August 8th, 2023. Please use Python version 3.8 and up.\n",
            "\n",
            "If you have a compatible Python interpreter installed, you can use it by setting\n",
            "the CLOUDSDK_PYTHON environment variable to point to it.\n",
            "\n",
            "WARNING:  Python 3.5-3.7 will be deprecated on August 8th, 2023. Please use Python version 3.8 and up.\n",
            "\n",
            "If you have a compatible Python interpreter installed, you can use it by setting\n",
            "the CLOUDSDK_PYTHON environment variable to point to it.\n",
            "\n",
            "WARNING:  Python 3.5-3.7 will be deprecated on August 8th, 2023. Please use Python version 3.8 and up.\n",
            "\n",
            "If you have a compatible Python interpreter installed, you can use it by setting\n",
            "the CLOUDSDK_PYTHON environment variable to point to it.\n",
            "\n",
            "WARNING:  Python 3.5-3.7 will be deprecated on August 8th, 2023. Please use Python version 3.8 and up.\n",
            "\n",
            "If you have a compatible Python interpreter installed, you can use it by setting\n",
            "the CLOUDSDK_PYTHON environment variable to point to it.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test task key 2053705a-2e39-483d-bac4-580b94bc20ce\n"
          ]
        }
      ],
      "source": [
        "model_input = [\n",
        "    InputRef(\n",
        "        identifier=\"models\",\n",
        "        parent_task_key=train_task_key,\n",
        "        parent_task_output_identifier=\"model\",\n",
        "    )\n",
        "]\n",
        "\n",
        "predict_task = TaskSpec(\n",
        "    function_key=predict_function_key,\n",
        "    inputs=data_manager_input + test_data_sample_inputs + model_input,\n",
        "    outputs={\"predictions\": ComputeTaskOutputSpec(permissions=permissions)},\n",
        "    worker=client.organization_info().organization_id,\n",
        ")\n",
        "\n",
        "predict_task_key = client.add_task(predict_task)\n",
        "\n",
        "predictions_input = [\n",
        "    InputRef(\n",
        "        identifier=\"predictions\",\n",
        "        parent_task_key=predict_task_key,\n",
        "        parent_task_output_identifier=\"predictions\",\n",
        "    )\n",
        "]\n",
        "\n",
        "test_task = TaskSpec(\n",
        "    function_key=metric_key,\n",
        "    inputs=data_manager_input + test_data_sample_inputs + predictions_input,\n",
        "    outputs={\"performance\": ComputeTaskOutputSpec(permissions=permissions)},\n",
        "    worker=client.organization_info().organization_id,\n",
        ")\n",
        "\n",
        "test_task_key = client.add_task(test_task)\n",
        "\n",
        "print(f\"Test task key {test_task_key}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results\n",
        "\n",
        "Now we can view the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test tasks status: Status.done\n",
            "Metric:  Testing with Accuracy metric\n",
            "Performance on the metric:  0.8212290502793296\n"
          ]
        }
      ],
      "source": [
        "from substra.sdk.models import Status\n",
        "import time\n",
        "\n",
        "test_task = client.get_task(test_task_key)\n",
        "while test_task.status != Status.done:\n",
        "    time.sleep(1)\n",
        "    test_task = client.get_task(test_task_key)\n",
        "\n",
        "print(f\"Test tasks status: {test_task.status}\")\n",
        "\n",
        "performance = client.get_task_output_asset(test_task.key, identifier=\"performance\")\n",
        "print(\"Metric: \", test_task.function.name)\n",
        "print(\"Performance on the metric: \", performance.asset)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
