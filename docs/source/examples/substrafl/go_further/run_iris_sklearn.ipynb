{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using scikit-learn FedAvg on IRIS dataset\n",
        "\n",
        "This example illustrate an advanced usage of SubstraFL as it does not use the SubstraFL PyTorch interface, but showcases the general SubstraFL interface that you can use with any ML framework.\n",
        "\n",
        "\n",
        "This example is based on:\n",
        "\n",
        "- Dataset: IRIS, tabular dataset to classify iris type\n",
        "- Model type: Logistic regression using Scikit-Learn\n",
        "- FL setup: three organizations, two data providers and one algo provider\n",
        "\n",
        "This example does not use the deployed platform of Substra, it runs in local mode.\n",
        "\n",
        "To run this example, you need to download and unzip the assets needed to run it in the same directory as used this example:\n",
        "\n",
        "- [assets required to run this example](../../../tmp/sklearn_fedavg_assets.zip)\n",
        "\n",
        "Please ensure to have all the libraries installed. A *requirements.txt* file is included in the zip file, where you can run the command `pip install -r requirements.txt` to install them.\n",
        "\n",
        "**Substra** and **SubstraFL** should already be installed. If not, follow the instructions described [here](https://docs.substra.org/en/stable/substrafl_doc/substrafl_overview.html#installation).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "We work with three different organizations. Two organizations provide a dataset, and a third\n",
        "one provides the algorithm and registers the machine learning tasks.\n",
        "\n",
        "This example runs in local mode, simulating a federated learning experiment.\n",
        "\n",
        "In the following code cell, we define the different organizations needed for our FL experiment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from substra import Client\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Choose the subprocess mode to locally simulate the FL process\n",
        "N_CLIENTS = 3\n",
        "clients_list = [Client(client_name=f\"org-{i+1}\") for i in range(N_CLIENTS)]\n",
        "clients = {client.organization_info().organization_id: client for client in clients_list}\n",
        "\n",
        "# Store organization IDs\n",
        "ORGS_ID = list(clients)\n",
        "ALGO_ORG_ID = ORGS_ID[0]  # Algo provider is defined as the first organization.\n",
        "DATA_PROVIDER_ORGS_ID = ORGS_ID[1:]  # Data provider orgs are the last two organizations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data and metrics\n",
        "\n",
        "### Data preparation\n",
        "\n",
        "This section downloads (if needed) the **IRIS dataset** using the [Scikit-Learn dataset module](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html).\n",
        "It extracts the data locally create two folders: one for each organization.\n",
        "\n",
        "Each organization will have access to half the train data, and to half the test data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "from sklearn_fedavg_assets.dataset.iris_dataset import setup_iris\n",
        "\n",
        "\n",
        "# Create the temporary directory for generated data\n",
        "(pathlib.Path.cwd() / \"tmp\").mkdir(exist_ok=True)\n",
        "data_path = pathlib.Path.cwd() / \"tmp\" / \"data_iris\"\n",
        "\n",
        "setup_iris(data_path=data_path, n_client=len(DATA_PROVIDER_ORGS_ID))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset registration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from substra.sdk.schemas import DatasetSpec\n",
        "from substra.sdk.schemas import Permissions\n",
        "from substra.sdk.schemas import DataSampleSpec\n",
        "\n",
        "assets_directory = pathlib.Path.cwd() / \"sklearn_fedavg_assets\"\n",
        "\n",
        "permissions_dataset = Permissions(public=False, authorized_ids=[ALGO_ORG_ID])\n",
        "\n",
        "dataset = DatasetSpec(\n",
        "    name=\"Iris\",\n",
        "    type=\"npy\",\n",
        "    data_opener=assets_directory / \"dataset\" / \"iris_opener.py\",\n",
        "    description=assets_directory / \"dataset\" / \"description.md\",\n",
        "    permissions=permissions_dataset,\n",
        "    logs_permission=permissions_dataset,\n",
        ")\n",
        "\n",
        "dataset_keys = {}\n",
        "train_datasample_keys = {}\n",
        "test_datasample_keys = {}\n",
        "\n",
        "for i, org_id in enumerate(DATA_PROVIDER_ORGS_ID):\n",
        "    client = clients[org_id]\n",
        "\n",
        "    # Add the dataset to the client to provide access to the opener in each organization.\n",
        "    dataset_keys[org_id] = client.add_dataset(dataset)\n",
        "    assert dataset_keys[org_id], \"Missing data manager key\"\n",
        "\n",
        "    client = clients[org_id]\n",
        "\n",
        "    # Add the training data on each organization.\n",
        "    data_sample = DataSampleSpec(\n",
        "        data_manager_keys=[dataset_keys[org_id]],\n",
        "        path=data_path / f\"org_{i+1}\" / \"train\",\n",
        "    )\n",
        "    train_datasample_keys[org_id] = client.add_data_sample(\n",
        "        data_sample,\n",
        "        local=True,\n",
        "    )\n",
        "\n",
        "    # Add the testing data on each organization.\n",
        "    data_sample = DataSampleSpec(\n",
        "        data_manager_keys=[dataset_keys[org_id]],\n",
        "        path=data_path / f\"org_{i+1}\" / \"test\",\n",
        "    )\n",
        "    test_datasample_keys[org_id] = client.add_data_sample(\n",
        "        data_sample,\n",
        "        local=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Metrics registration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def accuracy(data_from_opener, predictions):\n",
        "    y_true = data_from_opener[\"targets\"]\n",
        "\n",
        "    return accuracy_score(y_true, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Specify the machine learning components\n",
        "\n",
        "SubstraFL can be used with any machine learning framework. The framework\n",
        "dependent functions are written in the [Algorithm](https://docs.substra.org/en/stable/substrafl_doc/api/algorithms.html#algorithms) object.\n",
        "\n",
        "In this section, you will:\n",
        "\n",
        "- register a model and its dependencies\n",
        "- write your own Sklearn SubstraFL algorithm\n",
        "- specify the federated learning strategy\n",
        "- specify the organizations where to train and where to aggregate\n",
        "- specify the organizations where to test the models\n",
        "- actually run the computations\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model definition\n",
        "\n",
        "The machine learning model used here is a logistic regression.\n",
        "The `warm_start` argument is essential in this example as it indicates to use the current state of the model\n",
        "as initialization for the future training.\n",
        "By default scikit-learn uses `max_iter=100`, which means the model trains on up to 100 epochs.\n",
        "When doing federated learning, we don't want to train too much locally at every round\n",
        "otherwise the local training will erase what was learned from the other centers. That is why we set `max_iter=3`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from sklearn import linear_model\n",
        "\n",
        "cls = linear_model.LogisticRegression(random_state=SEED, warm_start=True, max_iter=3)\n",
        "\n",
        "# Optional:\n",
        "# Scikit-Learn raises warnings in case of non convergence, that we choose to disable here.\n",
        "# As this example runs with python subprocess, the way to disable it is to use following environment\n",
        "# variable:\n",
        "os.environ[\"PYTHONWARNINGS\"] = \"ignore:lbfgs failed to converge (status=1):UserWarning\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SubstraFL algo definition\n",
        "\n",
        "This section is the most important one for this example. We will define here the function that will run locally on\n",
        "each node to train the model.\n",
        "\n",
        "As SubstraFL does not provide an algorithm comptatible with Sklearn, we need to define one using the provided documentation on\n",
        "`substrafl_doc/api/algorithms:Base Class`.\n",
        "\n",
        "To define a custom algorithm, we will need to inherit from the base class Algo, and to define two properties and four\n",
        "methods:\n",
        "\n",
        "- **strategies** (property): the list of strategies our algorithm is compatible with.\n",
        "- **model** (property): a property that returns the model from the defined algo.\n",
        "- **train** (method): a function to describe the training process to\n",
        "  apply to train our model in a federated way.\n",
        "  The train method must accept as parameters `data_from_opener` and `shared_state`.\n",
        "- **predict** (method): a function to describe how to compute the\n",
        "  predictions from the algo model.\n",
        "  The predict method must accept as parameters `data_from_opener` and `shared_state`.\n",
        "- **save** (method): specify how to save the important states of our algo.\n",
        "- **load** (method): specify how to load the important states of our algo from a previously saved filed\n",
        "  by the `save` function describe above.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from substrafl import algorithms\n",
        "from substrafl import remote\n",
        "from substrafl.strategies import schemas as fl_schemas\n",
        "\n",
        "import joblib\n",
        "from typing import Optional\n",
        "\n",
        "# The Iris dataset proposes four attributes to predict three different classes.\n",
        "INPUT_SIZE = 4\n",
        "OUTPUT_SIZE = 3\n",
        "\n",
        "\n",
        "class SklearnLogisticRegression(algorithms.Algo):\n",
        "    def __init__(self, model, seed=None):\n",
        "        super().__init__(model=model, seed=seed)\n",
        "\n",
        "        self._model = model\n",
        "\n",
        "        # We need all different instances of the algorithm to have the same\n",
        "        # initialization.\n",
        "        self._model.coef_ = np.ones((OUTPUT_SIZE, INPUT_SIZE))\n",
        "        self._model.intercept_ = np.zeros(3)\n",
        "        self._model.classes_ = np.array([-1])\n",
        "\n",
        "        if seed is not None:\n",
        "            np.random.seed(seed)\n",
        "\n",
        "    @property\n",
        "    def strategies(self):\n",
        "        \"\"\"List of compatible strategies\"\"\"\n",
        "        return [fl_schemas.StrategyName.FEDERATED_AVERAGING]\n",
        "\n",
        "    @property\n",
        "    def model(self):\n",
        "        return self._model\n",
        "\n",
        "    @remote.remote_data\n",
        "    def train(\n",
        "        self,\n",
        "        data_from_opener,\n",
        "        shared_state: Optional[fl_schemas.FedAvgAveragedState] = None,\n",
        "    ) -> fl_schemas.FedAvgSharedState:\n",
        "        \"\"\"The train function to be executed on organizations containing\n",
        "        data we want to train our model on. The @remote_data decorator is mandatory\n",
        "        to allow this function to be sent and executed on the right organization.\n",
        "\n",
        "        Args:\n",
        "            data_from_opener: data_from_opener extracted from the organizations data using\n",
        "                the given opener.\n",
        "            shared_state (Optional[fl_schemas.FedAvgAveragedState], optional):\n",
        "                shared_state provided by the aggregator. Defaults to None.\n",
        "\n",
        "        Returns:\n",
        "            fl_schemas.FedAvgSharedState: State to be sent to the aggregator.\n",
        "        \"\"\"\n",
        "\n",
        "        if shared_state is not None:\n",
        "            # If we have a shared state, we update the model parameters with\n",
        "            # the average parameters updates.\n",
        "            self._model.coef_ += np.reshape(\n",
        "                shared_state.avg_parameters_update[:-1],\n",
        "                (OUTPUT_SIZE, INPUT_SIZE),\n",
        "            )\n",
        "            self._model.intercept_ += shared_state.avg_parameters_update[-1]\n",
        "\n",
        "        # To be able to compute the delta between the parameters before and after training,\n",
        "        # we need to save them in a temporary variable.\n",
        "        old_coef = self._model.coef_\n",
        "        old_intercept = self._model.intercept_\n",
        "\n",
        "        # Model training.\n",
        "        self._model.fit(data_from_opener[\"data\"], data_from_opener[\"targets\"])\n",
        "\n",
        "        # We compute de delta.\n",
        "        delta_coef = self._model.coef_ - old_coef\n",
        "        delta_bias = self._model.intercept_ - old_intercept\n",
        "\n",
        "        # We reset the model parameters to their state before training in order to remove\n",
        "        # the local updates from it.\n",
        "        self._model.coef_ = old_coef\n",
        "        self._model.intercept_ = old_intercept\n",
        "\n",
        "        # We output the length of the dataset to apply a weighted average between\n",
        "        # the organizations regarding their number of samples, and the local\n",
        "        # parameters updates.\n",
        "        # These updates are sent to the aggregator to compute the average\n",
        "        # parameters updates, that we will receive in the next round in the\n",
        "        # `shared_state`.\n",
        "        return fl_schemas.FedAvgSharedState(\n",
        "            n_samples=len(data_from_opener[\"targets\"]),\n",
        "            parameters_update=[p for p in delta_coef] + [delta_bias],\n",
        "        )\n",
        "\n",
        "    def predict(self, data_from_opener, shared_state):\n",
        "        \"\"\"The predict function to be executed by the evaluation function on\n",
        "        data we want to test our model on. The predict method is mandatory and is\n",
        "        an `abstractmethod` of the `Algo` class.\n",
        "\n",
        "        Args:\n",
        "            data_from_opener: data_from_opener extracted from the organizations data using\n",
        "                the given opener.\n",
        "            shared_state: shared_state provided by the aggregator.\n",
        "        \"\"\"\n",
        "        predictions = self._model.predict(data_from_opener[\"data\"])\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def save_local_state(self, path):\n",
        "        joblib.dump(\n",
        "            {\n",
        "                \"model\": self._model,\n",
        "                \"coef\": self._model.coef_,\n",
        "                \"bias\": self._model.intercept_,\n",
        "            },\n",
        "            path,\n",
        "        )\n",
        "\n",
        "    def load_local_state(self, path):\n",
        "        loaded_dict = joblib.load(path)\n",
        "        self._model = loaded_dict[\"model\"]\n",
        "        self._model.coef_ = loaded_dict[\"coef\"]\n",
        "        self._model.intercept_ = loaded_dict[\"bias\"]\n",
        "        return self"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Federated Learning strategies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from substrafl.strategies import FedAvg\n",
        "\n",
        "strategy = FedAvg(algo=SklearnLogisticRegression(model=cls, seed=SEED), metric_functions=accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Where to train where to aggregate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from substrafl.nodes import TrainDataNode\n",
        "from substrafl.nodes import AggregationNode\n",
        "\n",
        "\n",
        "aggregation_node = AggregationNode(ALGO_ORG_ID)\n",
        "\n",
        "# Create the Train Data Nodes (or training tasks) and save them in a list\n",
        "train_data_nodes = [\n",
        "    TrainDataNode(\n",
        "        organization_id=org_id,\n",
        "        data_manager_key=dataset_keys[org_id],\n",
        "        data_sample_keys=[train_datasample_keys[org_id]],\n",
        "    )\n",
        "    for org_id in DATA_PROVIDER_ORGS_ID\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Where and when to test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from substrafl.nodes import TestDataNode\n",
        "from substrafl.evaluation_strategy import EvaluationStrategy\n",
        "\n",
        "# Create the Test Data Nodes (or testing tasks) and save them in a list\n",
        "test_data_nodes = [\n",
        "    TestDataNode(\n",
        "        organization_id=org_id,\n",
        "        data_manager_key=dataset_keys[org_id],\n",
        "        data_sample_keys=[test_datasample_keys[org_id]],\n",
        "    )\n",
        "    for org_id in DATA_PROVIDER_ORGS_ID\n",
        "]\n",
        "\n",
        "my_eval_strategy = EvaluationStrategy(test_data_nodes=test_data_nodes, eval_frequency=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from substrafl.experiment import execute_experiment\n",
        "from substrafl.dependency import Dependency\n",
        "\n",
        "# Number of times to apply the compute plan.\n",
        "NUM_ROUNDS = 6\n",
        "\n",
        "dependencies = Dependency(pypi_dependencies=[\"numpy==1.24.3\", \"scikit-learn==1.3.1\"])\n",
        "\n",
        "compute_plan = execute_experiment(\n",
        "    client=clients[ALGO_ORG_ID],\n",
        "    strategy=strategy,\n",
        "    train_data_nodes=train_data_nodes,\n",
        "    evaluation_strategy=my_eval_strategy,\n",
        "    aggregation_node=aggregation_node,\n",
        "    num_rounds=NUM_ROUNDS,\n",
        "    experiment_folder=str(pathlib.Path.cwd() / \"tmp\" / \"experiment_summaries\"),\n",
        "    dependencies=dependencies,\n",
        "    name=\"IRIS documentation example\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explore the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# The results will be available once the compute plan is completed\n",
        "clients[ALGO_ORG_ID].wait_compute_plan(compute_plan.key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Listing results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "performances_df = pd.DataFrame(client.get_performances(compute_plan.key).model_dump())\n",
        "print(\"\\nPerformance Table: \\n\")\n",
        "print(performances_df[[\"worker\", \"round_idx\", \"performance\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.title(\"Test dataset results\")\n",
        "plt.xlabel(\"Rounds\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "\n",
        "for org_id in DATA_PROVIDER_ORGS_ID:\n",
        "    df = performances_df[performances_df[\"worker\"] == org_id]\n",
        "    plt.plot(df[\"round_idx\"], df[\"performance\"], label=org_id)\n",
        "\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from substrafl.model_loading import download_algo_state\n",
        "\n",
        "client_to_download_from = DATA_PROVIDER_ORGS_ID[0]\n",
        "round_idx = None\n",
        "\n",
        "algo = download_algo_state(\n",
        "    client=clients[client_to_download_from],\n",
        "    compute_plan_key=compute_plan.key,\n",
        "    round_idx=round_idx,\n",
        ")\n",
        "\n",
        "cls = algo.model\n",
        "\n",
        "print(\"Coefs: \", cls.coef_)\n",
        "print(\"Intercepts: \", cls.intercept_)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
